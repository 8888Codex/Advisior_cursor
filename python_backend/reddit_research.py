"""
Reddit Research Engine - Strategic Community Analysis
Analyzes Reddit communities to extract persona insights using Perplexity API and Claude
"""
import os
import time
import json
import random
import re
from typing import Dict, List, Optional, Any
import httpx
import asyncio
from dotenv import load_dotenv, find_dotenv
from anthropic import AsyncAnthropic

# Carregar .env quando o m√≥dulo √© importado
_env_file = find_dotenv(usecwd=True)
if _env_file:
    load_dotenv(_env_file, override=True)

class RedditResearchEngine:
    """
    Researches target audience using Perplexity API and synthesizes with Claude.
    
    Features:
    - Robust error handling
    - Structured data output
    - Framework-based persona generation (JTBD + BAG)
    """
    
    def __init__(self):
        self._perplexity_api_key = None
        self._anthropic_client = None
        self._cache = {}  # Simple in-memory cache
        self._cache_ttl = 24 * 60 * 60  # 24 hours in seconds
    
    def _ensure_initialized(self):
        """Lazy initialization of API clients"""
        # Garantir que .env est√° carregado
        _env_file = find_dotenv(usecwd=True)
        if _env_file:
            load_dotenv(_env_file, override=True)
        
        if self._perplexity_api_key is None:
            self._perplexity_api_key = os.getenv("PERPLEXITY_API_KEY") or os.environ.get("PERPLEXITY_API_KEY")
            if not self._perplexity_api_key:
                raise ValueError("PERPLEXITY_API_KEY environment variable not set")
        
        if self._anthropic_client is None:
            anthropic_key = os.getenv("ANTHROPIC_API_KEY") or os.environ.get("ANTHROPIC_API_KEY")
            if not anthropic_key:
                raise ValueError(
                    "ANTHROPIC_API_KEY environment variable not set. "
                    "Verifique se o arquivo .env existe e cont√©m ANTHROPIC_API_KEY=sk-ant-... "
                    "ou configure como vari√°vel de ambiente do sistema."
                )
            self._anthropic_client = AsyncAnthropic(api_key=anthropic_key)
    
    def _get_cache_key(self, method: str, **kwargs) -> str:
        """Generate a cache key from method name and arguments"""
        # Sort kwargs to ensure consistent keys
        sorted_kwargs = {k: kwargs[k] for k in sorted(kwargs.keys()) if kwargs[k] is not None}
        return f"{method}:{json.dumps(sorted_kwargs)}"
    
    def _get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """Get result from cache if it exists and is not expired"""
        if cache_key in self._cache:
            timestamp, data = self._cache[cache_key]
            if time.time() - timestamp < self._cache_ttl:
                print(f"[RedditResearch] Cache hit for {cache_key}")
                return data
            else:
                print(f"[RedditResearch] Cache expired for {cache_key}")
                del self._cache[cache_key]
        return None
    
    def _set_cache_result(self, cache_key: str, data: Dict):
        """Store result in cache with current timestamp"""
        self._cache[cache_key] = (time.time(), data)
    
    async def _call_perplexity_api(self, query: str, model: str = "sonar-reasoning") -> Dict:
        """
        Call Perplexity API with fallback models
        
        Args:
            query: The search query
            model: Perplexity model to use
            
        Returns:
            Dict containing the API response
        """
        self._ensure_initialized()
        
        # Lista de modelos para fallback em ordem de prefer√™ncia
        fallback_models = ["sonar-reasoning", "sonar", "sonar-pro", "sonar-deep-research", "sonar-reasoning-pro"]
        
        # Se o modelo solicitado n√£o estiver na lista de fallback, adicione-o como primeira op√ß√£o
        if model not in fallback_models:
            fallback_models.insert(0, model)
        else:
            # Se o modelo j√° estiver na lista, reorganize para que seja o primeiro
            fallback_models.remove(model)
            fallback_models.insert(0, model)
            
        last_error = None
        
        # Tente cada modelo na lista de fallback
        for current_model in fallback_models:
            try:
                print(f"[RedditResearch] Calling Perplexity API with model {current_model}...")
                
                request_payload = {
                    "model": current_model,
                    "messages": [
                        {"role": "system", "content": "Voc√™ √© um especialista em pesquisa de audi√™ncia. Forne√ßa insights concretos e acion√°veis baseados em dados reais."},
                        {"role": "user", "content": query}
                    ],
                    "temperature": 0.2,
                    "max_tokens": 2000
                }
                
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        "https://api.perplexity.ai/chat/completions",
                        headers={
                            "Authorization": f"Bearer {self._perplexity_api_key}",
                            "Content-Type": "application/json"
                        },
                        json=request_payload
                    )
                    
                    response.raise_for_status()  # Raise exception for 4XX/5XX responses
                    
                    result = response.json()
                    print(f"[RedditResearch] Successfully used model {current_model}")
                    return result
                    
            except httpx.HTTPStatusError as e:
                print(f"[RedditResearch] Perplexity API HTTP error with model {current_model}: {e.response.status_code} - {e.response.text}")
                last_error = e
                continue  # Try next model
                
            except httpx.RequestError as e:
                print(f"[RedditResearch] Perplexity API request error with model {current_model}: {str(e)}")
                last_error = e
                continue  # Try next model
                
            except Exception as e:
                print(f"[RedditResearch] Unexpected error with model {current_model}: {str(e)}")
                last_error = e
                continue  # Try next model
        
        # If we've tried all models and none worked, check if it's a resource_exhausted error
        if last_error:
            print(f"[RedditResearch] All fallback models failed. Last error: {str(last_error)}")
            
            # If it's an HTTPStatusError, pass it through so it can be handled properly
            if isinstance(last_error, httpx.HTTPStatusError):
                if "resource_exhausted" in last_error.response.text.lower():
                    print("[RedditResearch] Resource exhausted error detected")
                raise last_error
                
            raise ValueError(f"All Perplexity API models failed: {str(last_error)}")
        
        # This should never happen, but just in case
        raise ValueError("Failed to call Perplexity API with all available models")
    
    async def _call_anthropic_api(self, prompt: str) -> Dict:
        """
        Call Claude API to structure data
        
        Args:
            prompt: The prompt to send to Claude
            
        Returns:
            Dict containing the structured data
        """
        self._ensure_initialized()
        
        try:
            # Call Claude API with retry logic for network issues
            retry_count = 0
            max_retries = 3
            backoff_factor = 1.5
            
            while retry_count <= max_retries:
                try:
                    message = await self._anthropic_client.messages.create(
                        model="claude-3-haiku-20240307",
                        max_tokens=4000,
                        temperature=0.2,
                        system="Voc√™ √© um assistente especializado em estruturar dados de pesquisa em formatos JSON.",
                        messages=[
                            {"role": "user", "content": prompt}
                        ]
                    )
                    break  # Success, exit retry loop
                except Exception as retry_error:
                    retry_count += 1
                    if retry_count > max_retries:
                        print(f"[RedditResearch] Max retries ({max_retries}) reached. Giving up.")
                        raise  # Re-raise the last exception
                    
                    wait_time = backoff_factor ** retry_count
                    print(f"[RedditResearch] Retry {retry_count}/{max_retries} after error: {str(retry_error)}. Waiting {wait_time:.1f}s")
                    await asyncio.sleep(wait_time)
            
            
            content = message.content[0].text
            
            # Try to extract JSON from the response
            try:
                # First try to find JSON in code blocks
                json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                    return json.loads(json_str)
                
                # If not found in code blocks, try to find anything that looks like JSON
                json_match = re.search(r'({.*})', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                    return json.loads(json_str)
                
                print("[RedditResearch] Failed to parse JSON from Claude response, using full text")
            except json.JSONDecodeError:
                print("[RedditResearch] Failed to parse JSON from Claude response, using full text")
            
            # If not valid JSON or not in code blocks, return the raw text
            return {"content": content}
            
        except Exception as e:
            print(f"[RedditResearch] Claude API error: {str(e)}")
            raise
    
    async def research_quick(self, target_description: str, industry: Optional[str] = None) -> Dict:
        """
        Quick research mode: Uses Perplexity for research and Claude for structuring
        
        Args:
            target_description: Description of the target audience
            industry: Optional industry context
            
        Returns:
            Dict with structured persona data following JTBD and BAG frameworks
        """
        try:
            # Check cache first
            cache_key = self._get_cache_key("research_quick", target_description=target_description, industry=industry)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                print(f"[RedditResearch] Cache hit for '{target_description}'")
                return cached_result
            
            print(f"[RedditResearch] Iniciando pesquisa r√°pida para '{target_description}'")
            
            # Build Perplexity query for JTBD + BAG framework
            context = f"na ind√∫stria de {industry}" if industry else ""
            query = f"""
Pesquise informa√ß√µes detalhadas sobre o p√∫blico-alvo '{target_description}' {context}, focando em:

1. Jobs to Be Done (JTBD):
   - Quais s√£o os principais "trabalhos" que este p√∫blico precisa realizar?
   - Quais contextos situacionais desencadeiam esses trabalhos?
   - Quais s√£o os trabalhos funcionais, emocionais e sociais?

2. Comportamentos, Aspira√ß√µes e Objetivos (BAG):
   - Comportamentos observ√°veis e padr√µes de uso
   - Aspira√ß√µes de longo prazo e sonhos
   - Objetivos espec√≠ficos de curto e m√©dio prazo

3. Elementos Quantitativos:
   - Pontos de dor com impacto mensur√°vel (tempo, dinheiro, estresse)
   - Crit√©rios de decis√£o com pesos relativos
   - M√©tricas de sucesso para avaliar solu√ß√µes

4. Jornada e Pontos de Contato:
   - Canais preferidos para diferentes est√°gios
   - Tipos de conte√∫do mais valorizados
   - Influenciadores e fontes confi√°veis

Forne√ßa dados espec√≠ficos, estat√≠sticas quando poss√≠vel, e cite fontes relevantes.
"""
            
            # Call Perplexity API
            perplexity_result = await self._call_perplexity_api(query)
            perplexity_content = perplexity_result["choices"][0]["message"]["content"]
            
            # Now use Claude to structure the data
            claude_prompt = f"""
Voc√™ √© um especialista em cria√ß√£o de personas de marketing de alta precis√£o.

INPUT DO USU√ÅRIO (pode ser vago):
- Descri√ß√£o: "{target_description}"
- Ind√∫stria: {context if context else "n√£o especificada"}

DADOS DE PESQUISA:
{perplexity_content}

AN√ÅLISE CR√çTICA DO INPUT:
1. O input √© vago ou gen√©rico? Se sim, USE OS DADOS DE PESQUISA para INFERIR detalhes espec√≠ficos
2. Faltam cargos espec√≠ficos? DEDUZA baseado no contexto (budget, team size, ind√∫stria)
3. Sem setor definido? IDENTIFIQUE o setor mais prov√°vel baseado nas caracter√≠sticas

TAREFA:
Crie uma persona ULTRA-ESPEC√çFICA seguindo os frameworks modernos de 2025:

PRINC√çPIOS OBRIGAT√ìRIOS:
1. NUNCA seja gen√©rico - sempre espec√≠fico
2. INFIRA detalhes que o usu√°rio n√£o mencionou mas s√£o l√≥gicos
3. QUANTIFIQUE tudo que for poss√≠vel (tempo, dinheiro, frequ√™ncia)
4. Use DADOS REAIS da pesquisa, n√£o suposi√ß√µes gen√©ricas
5. Comece com job statement claro e acion√°vel
6. Estruture usando framework BAG completo (Behaviors, Aspirations, Goals)
7. Inclua elementos quantitativos DETALHADOS para todos os pontos de dor
8. Mapeie jornada moderna com todos os pontos de contato

EXPANS√ÉO INTELIGENTE:
Se input diz "profissionais B2B" ‚Üí Identifique CARGOS espec√≠ficos (CMO, Diretor, Head)
Se menciona "10k/m√™s em ads" ‚Üí Infira faturamento, tamanho empresa, maturidade
Se n√£o menciona setor ‚Üí Use padr√µes da pesquisa para identificar setor prov√°vel

Formate os dados no seguinte formato JSON:
{{
  "job_statement": "string",
  "functional_jobs": ["string"],
  "emotional_jobs": ["string"],
  "social_jobs": ["string"],
  "behaviors": {{
    "online": ["string"],
    "purchasing": ["string"],
    "content_consumption": ["string"]
  }},
  "aspirations": ["string"],
  "goals": [
    {{
      "description": "string",
      "timeframe": "short|medium|long",
      "success_metrics": ["string"]
    }}
  ],
  "demographics": {{
    "age": "string",
    "location": "string",
    "occupation": "string",
    "education": "string",
    "income": "string"
  }},
  "psychographics": {{
    "values": ["string"],
    "interests": ["string"],
    "personality_traits": ["string"]
  }},
  "pain_points_quantified": [
    {{
      "description": "string",
      "impact": "string",
      "cost": "string",
      "frequency": "string"
    }}
  ],
  "values": ["string"],
  "content_preferences": {{
    "formats": ["string"],
    "topics": ["string"],
    "channels": ["string"]
  }},
  "touchpoints": [
    {{
      "channel": "string",
      "stage": "string",
      "importance": 1-10,
      "preferred_content": ["string"]
    }}
  ],
  "researchData": {{
    "sources": ["string"],
    "confidence_level": "high|medium|low",
    "timestamp": "ISO date string"
  }}
}}

Importante: Todos os dados devem ser espec√≠ficos, acion√°veis e baseados na pesquisa.
"""
            
            # Call Claude API to structure the data
            structured_data = await self._call_anthropic_api(claude_prompt)
            
            # Add metadata
            if "researchData" not in structured_data:
                structured_data["researchData"] = {}
            
            structured_data["researchData"]["generated_at"] = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
            structured_data["researchData"]["target_description"] = target_description
            if industry:
                structured_data["researchData"]["industry"] = industry
            
            # Cache the result
            self._set_cache_result(cache_key, structured_data)
            
            print(f"[RedditResearch] Pesquisa r√°pida conclu√≠da com sucesso para '{target_description}'")
            return structured_data
            
        except Exception as e:
            print(f"[RedditResearch] Error in quick research: {str(e)}")
            
            # Fornecer dados de fallback para evitar erro 500
            print(f"[RedditResearch] Gerando dados de fallback para '{target_description}'")
            
            fallback_data = {
                "job_statement": f"Ajudar {target_description} a ter sucesso em seus objetivos profissionais",
                "functional_jobs": ["Economizar tempo", "Aumentar produtividade"],
                "emotional_jobs": ["Reduzir estresse", "Aumentar confian√ßa"],
                "social_jobs": ["Ser reconhecido por pares", "Demonstrar compet√™ncia"],
                "behaviors": {
                    "online": ["Pesquisa por solu√ß√µes online", "Consome conte√∫do educativo"],
                    "purchasing": ["Compara op√ß√µes", "Busca recomenda√ß√µes"],
                    "content_consumption": ["Prefere conte√∫do pr√°tico", "Consome em m√∫ltiplos formatos"]
                },
                "aspirations": [
                    f"Ser reconhecido como expert em {industry or 'seu campo'}",
                    "Alcan√ßar equil√≠brio entre vida pessoal e profissional"
                ],
                "demographics": {
                    "age": "30-45 anos",
                    "location": "Centros urbanos",
                    "education": "Ensino superior completo",
                    "income": "Classe m√©dia a alta",
                    "occupation": "Profissional freelancer"
                },
                "pain_points_quantified": [
                    {
                        "description": "Dificuldade em acompanhar tend√™ncias do mercado",
                        "impact": "Perda de oportunidades de neg√≥cio",
                        "frequency": "Constante"
                    }
                ],
                "research_data": {
                    "generated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    "target_description": target_description,
                    "confidence_level": "low",
                    "is_fallback": True
                }
            }
            
            if industry:
                fallback_data["research_data"]["industry"] = industry
                
            # Cache o resultado de fallback tamb√©m
            self._set_cache_result(cache_key, fallback_data)
            
            return fallback_data

    async def research_strategic(self, target_description: str, industry: Optional[str] = None, additional_context: Optional[str] = None) -> Dict:
        """
        Strategic research mode: DEEP comprehensive research with multiple API calls
        
        Args:
            target_description: Description of the target audience
            industry: Optional industry context
            additional_context: Additional context to refine the research
        
        Returns:
            Dict with comprehensive persona data with REAL insights
        """
        try:
            # Check cache first
            cache_key = self._get_cache_key("research_strategic", target_description=target_description, industry=industry, additional_context=additional_context)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                return cached_result
            
            print(f"[RedditResearch] üîç MODO ESTRAT√âGICO - Pesquisa profunda para '{target_description}'")
            self._ensure_initialized()
            
            context = f"na ind√∫stria de {industry}" if industry else ""
            additional = f". {additional_context}" if additional_context else ""
            
            # ============================================================================
            # FASE 1: DESCOBERTA DE COMUNIDADES E FONTES (Primeira chamada Perplexity)
            # ============================================================================
            discovery_query = f"""Pesquise profundamente sobre {target_description} {context}{additional}.

TAREFA 1 - DESCOBERTA:
Identifique COMUNIDADES REAIS onde este p√∫blico est√° ativo:
- Subreddits espec√≠ficos (ex: r/marketing, r/startups, r/entrepreneur)
- F√≥runs e grupos online
- Comunidades profissionais
- Canais e influenciadores que seguem

RETORNE:
1. Lista de 5-10 comunidades espec√≠ficas com URLs
2. Principais t√≥picos discutidos
3. Principais preocupa√ß√µes e dores mencionadas
4. Linguagem e termos que usam"""

            print(f"[RedditResearch] üìä Fase 1: Descobrindo comunidades...")
            discovery_response = await self._call_perplexity_api(discovery_query)
            discovery_text = self._extract_content_from_response(discovery_response)
            
            # ============================================================================
            # FASE 2: AN√ÅLISE PROFUNDA DE PAIN POINTS (Segunda chamada Perplexity)
            # ============================================================================
            pain_points_query = f"""Baseado no p√∫blico {target_description} {context}{additional}, fa√ßa uma an√°lise QUANTIFICADA e ESPEC√çFICA.

TAREFA 2 - PAIN POINTS QUANTIFICADOS:
Identifique problemas REAIS com N√öMEROS:
- Custos espec√≠ficos (ex: CAC de R$X, tempo de Y horas/semana)
- Impactos mensur√°veis (ex: perda de X% de leads, Y% de churn)
- Frequ√™ncia dos problemas (di√°rio, semanal, mensal)
- ROI e m√©tricas que acompanham

RETORNE:
1. Top 5 pain points com custos estimados
2. Impacto financeiro de cada problema
3. Frequ√™ncia de ocorr√™ncia
4. M√©tricas que mais monitoram"""

            print(f"[RedditResearch] üí∞ Fase 2: Analisando pain points quantificados...")
            pain_response = await self._call_perplexity_api(pain_points_query)
            pain_text = self._extract_content_from_response(pain_response)
            
            # ============================================================================
            # FASE 3: COMPORTAMENTOS E DECIS√ïES (Terceira chamada Perplexity)
            # ============================================================================
            behavior_query = f"""Pesquise o comportamento de compra e decis√£o de {target_description} {context}{additional}.

TAREFA 3 - COMPORTAMENTOS REAIS:
Identifique padr√µes de decis√£o e a√ß√£o:
- Como pesquisam solu√ß√µes (canais, ferramentas, processos)
- Crit√©rios de decis√£o (pre√ßo, features, suporte, etc)
- Influenciadores e fontes de confian√ßa
- Obje√ß√µes t√≠picas e medos
- Ciclo de decis√£o (tempo m√©dio, etapas)

RETORNE:
1. Processo de pesquisa detalhado
2. Crit√©rios de decis√£o priorizados
3. Principais obje√ß√µes
4. Tempo m√©dio de decis√£o"""

            print(f"[RedditResearch] üéØ Fase 3: Mapeando comportamentos e decis√µes...")
            behavior_response = await self._call_perplexity_api(behavior_query)
            behavior_text = self._extract_content_from_response(behavior_response)
            
            # ============================================================================
            # FASE 4: S√çNTESE COM CLAUDE (Quarta chamada - Claude)
            # ============================================================================
            print(f"[RedditResearch] ü§ñ Fase 4: Sintetizando com Claude...")
            
            synthesis_prompt = f"""Voc√™ √© um especialista em personas B2B e an√°lise de p√∫blico-alvo com 15+ anos de experi√™ncia.

Recebi 3 pesquisas profundas sobre: {target_description} {context}{additional}

DESCOBERTA DE COMUNIDADES:
{discovery_text}

PAIN POINTS QUANTIFICADOS:
{pain_text}

COMPORTAMENTOS E DECIS√ïES:
{behavior_text}

TAREFA FINAL:
Crie uma persona ULTRA-ESPEC√çFICA e ESTRAT√âGICA no formato JSON:

{{
  "job_statement": "Job to be done principal (espec√≠fico e acion√°vel)",
  "functional_jobs": ["5-7 jobs funcionais ESPEC√çFICOS"],
  "emotional_jobs": ["4-5 jobs emocionais REAIS"],
  "social_jobs": ["3-4 jobs sociais ESPEC√çFICOS"],
  "behaviors": {{
    "online": ["5-7 comportamentos online ESPEC√çFICOS com ferramentas/plataformas"],
    "purchasing": ["4-5 comportamentos de compra DETALHADOS"],
    "content_consumption": ["4-5 prefer√™ncias de conte√∫do ESPEC√çFICAS"]
  }},
  "aspirations": ["4-5 aspira√ß√µes ESPEC√çFICAS E AMBICIOSAS"],
  "goals": ["5-7 objetivos MENSUR√ÅVEIS com n√∫meros"],
  "pain_points_quantified": [
    {{
      "description": "Pain point ESPEC√çFICO",
      "impact": "Impacto MENSUR√ÅVEL",
      "cost": "Custo ESTIMADO em R$ ou tempo",
      "frequency": "Frequ√™ncia ESPEC√çFICA (di√°ria/semanal/mensal)"
    }}
  ],
  "decision_criteria": {{
    "must_have": ["3-5 crit√©rios ESSENCIAIS"],
    "nice_to_have": ["2-3 crit√©rios DESEJ√ÅVEIS"],
    "deal_breakers": ["2-3 ELIMINAT√ìRIOS"]
  }},
  "demographics": {{
    "age": "Faixa et√°ria ESPEC√çFICA",
    "location": "Localiza√ß√µes ESPEC√çFICAS",
    "occupation": "Cargos ESPEC√çFICOS",
    "education": "N√≠vel ESPEC√çFICO",
    "income": "Faixa salarial ESPEC√çFICA em R$"
  }},
  "values": ["4-5 valores ESPEC√çFICOS"],
  "touchpoints": [
    {{
      "channel": "Canal ESPEC√çFICO",
      "stage": "awareness/consideration/decision",
      "importance": 1-10,
      "preferred_content": ["tipos de conte√∫do ESPEC√çFICOS"]
    }}
  ],
  "content_preferences": {{
    "formats": ["formatos ESPEC√çFICOS"],
    "topics": ["t√≥picos ESPEC√çFICOS"],
    "channels": ["canais ESPEC√çFICOS"],
    "influencers": ["influenciadores ESPEC√çFICOS se mencionados"]
  }},
  "communities": ["5-10 comunidades ESPEC√çFICAS com URLs se poss√≠vel"]
}}

REGRAS OBRIGAT√ìRIAS:
1. SEMPRE incluir N√öMEROS e QUANTIFICA√á√ïES
2. SEMPRE ser ESPEC√çFICO (n√£o gen√©rico)
3. SEMPRE basear nas pesquisas fornecidas
4. SEMPRE incluir custos estimados nos pain points
5. SEMPRE detalhar crit√©rios de decis√£o

RETORNE APENAS O JSON, SEM MARKDOWN OU EXPLICA√á√ïES."""

            claude_response = await self._anthropic_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=4000,
                temperature=0.3,  # Mais determin√≠stico para dados estruturados
                messages=[{"role": "user", "content": synthesis_prompt}]
            )
            
            result_text = claude_response.content[0].text.strip()
            
            # Remover markdown se presente
            if result_text.startswith("```json"):
                result_text = result_text.replace("```json", "").replace("```", "").strip()
            elif result_text.startswith("```"):
                result_text = result_text.replace("```", "").strip()
            
            # Parse JSON
            result = json.loads(result_text)
            
            # Adicionar metadata da pesquisa
            result["research_data"] = {
                "sources": self._extract_sources_from_response(discovery_response),
                "confidence_level": "high",  # Pesquisa profunda = alta confian√ßa
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                "generated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                "target_description": target_description,
                "industry": industry,
                "additional_context": additional_context,
                "research_depth": "strategic",
                "perplexity_calls": 3,
                "claude_synthesis": True
            }
            
            # Cache the result
            self._set_cache_result(cache_key, result)
            
            print(f"[RedditResearch] ‚úÖ Pesquisa estrat√©gica conclu√≠da com ALTA qualidade!")
            
            return result
                
        except Exception as e:
            print(f"[RedditResearch] ‚ùå Error in strategic research: {str(e)}")
            
            # Provide fallback data
            fallback_data = {
                "job_statement": f"Ajudar {target_description} a ter sucesso em seus objetivos profissionais",
                "functional_jobs": ["Economizar tempo", "Aumentar produtividade"],
                "emotional_jobs": ["Reduzir estresse", "Aumentar confian√ßa"],
                "social_jobs": ["Ser reconhecido por pares", "Demonstrar compet√™ncia"],
                "behaviors": {
                    "online": ["Pesquisa por solu√ß√µes online", "Consome conte√∫do educativo"],
                    "purchasing": ["Compara op√ß√µes", "Busca recomenda√ß√µes"],
                    "content_consumption": ["Prefere conte√∫do pr√°tico", "Consome em m√∫ltiplos formatos"]
                },
                "aspirations": [
                    f"Ser reconhecido como expert em {industry or 'seu campo'}",
                    "Alcan√ßar equil√≠brio entre vida pessoal e profissional"
                ],
                "goals": ["Aumentar visibilidade online", "Melhorar convers√µes", "Desenvolver habilidades t√©cnicas"],
                "demographics": {
                    "age": "30-45 anos",
                    "location": "Centros urbanos",
                    "education": "Ensino superior completo",
                    "income": "Classe m√©dia a alta",
                    "occupation": "Profissional"
                },
                "pain_points_quantified": [
                    {
                        "description": "Dificuldade em acompanhar tend√™ncias do mercado",
                        "impact": "Perda de oportunidades de neg√≥cio",
                        "frequency": "Constante"
                    }
                ],
                "research_data": {
                    "generated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    "target_description": target_description,
                    "confidence_level": "low",
                    "is_fallback": True,
                    "error": str(e)
                }
            }
            
            if industry:
                fallback_data["research_data"]["industry"] = industry
            if additional_context:
                fallback_data["research_data"]["additional_context"] = additional_context
                
            # Cache o resultado de fallback tamb√©m
            self._set_cache_result(cache_key, fallback_data)
            
            return fallback_data

# Singleton instance
reddit_research = RedditResearchEngine()
